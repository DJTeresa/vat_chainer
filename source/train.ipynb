{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from chainer import Variable, optimizers,cuda\n",
    "import chainer.functions as F\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy\n",
    "from virtual_adversarial_trainer import VirtualAdversarialTrainer\n",
    "from my_batch_normalization import MyBatchNormalization\n",
    "from nn import NN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class stdNN(NN):\n",
    "    def __init__(self):\n",
    "        super(NN,self).__init__(l1 = F.Linear(784,1200,nobias=True),\n",
    "                                b1 = MyBatchNormalization(1200, decay=0.9, eps=1e-06),\n",
    "                                l2 = F.Linear(1200,600,nobias=True),\n",
    "                                b2 = MyBatchNormalization(600, decay=0.9, eps=1e-06),\n",
    "                                l3 = F.Linear(600,300,nobias=True),\n",
    "                                b3 = MyBatchNormalization(300, decay=0.9, eps=1e-06),\n",
    "                                l4 =F.Linear(300,150,nobias=True),\n",
    "                                b4 = MyBatchNormalization(150, decay=0.9, eps=1e-06),\n",
    "                                l5 =F.Linear(150,10),\n",
    "                                b5 = MyBatchNormalization(10, decay=0.9, eps=1e-06))\n",
    "        self.to_gpu()\n",
    "    def y_given_x(self,x,test,upd_batch_est=True):\n",
    "        h = self.l1(x)\n",
    "        h = self.b1(h,test,False,upd_batch_est)\n",
    "        h = F.relu(h)\n",
    "        h = self.l2(h)\n",
    "        h = self.b2(h,test,False,upd_batch_est)\n",
    "        h = F.relu(h)\n",
    "        h = self.l3(h)\n",
    "        h = self.b3(h,test,False,upd_batch_est)\n",
    "        h = F.relu(h)\n",
    "        h = self.l4(h)\n",
    "        h = self.b4(h,test,False,upd_batch_est)\n",
    "        h = F.relu(h)\n",
    "        h = self.l5(h)\n",
    "        h = self.b5(h,test,False,upd_batch_est)\n",
    "        return h\n",
    "    \n",
    "    def py_given_y(self,y):\n",
    "        return F.softmax(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Initialize NN and virtual adversarial trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numpy.random.seed(1)\n",
    "cuda.init()\n",
    "model = stdNN()\n",
    "virtual_adversarial_trainer = VirtualAdversarialTrainer(model,out_act_type='Softmax',epsilon=2.1,\n",
    "                                                                            norm_constraint_type='L2',lamb=numpy.float(1.0),\n",
    "                                                                            xi=numpy.float(1e-6),num_power_iteration=1)\n",
    "optimizer = optimizers.Adam(alpha=0.002)\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "x_all = mnist.data.astype(numpy.float32) / 255\n",
    "y_all = mnist.target.astype(numpy.int32)\n",
    "x_train, x_test = numpy.split(x_all, [60000])\n",
    "y_train, y_test = numpy.split(y_all, [60000])\n",
    "optimizer.setup(model.collect_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "virtual_adversarial_training = True\n",
    "\n",
    "batchsize = 100 \n",
    "for epoch in xrange(100):\n",
    "    indexes = numpy.random.permutation(60000)\n",
    "    n_batch = indexes.shape[0]/batchsize\n",
    "    sum_nll = 0\n",
    "    sum_cost_vadv = 0\n",
    "    sum_accuracy = 0\n",
    "\n",
    "    for i in xrange(0, 60000, batchsize):\n",
    "        x_batch = Variable(cuda.to_gpu(x_train[indexes[i : i + batchsize]]))\n",
    "        y_batch = Variable(cuda.to_gpu(y_train[indexes[i : i + batchsize]]))\n",
    "        nll, cost_vadv= virtual_adversarial_trainer.cost_virtual_adversarial_training(x_batch,y_batch,unchain_clean_y=True)\n",
    "        sum_nll += nll.data*batchsize\n",
    "        sum_cost_vadv += cost_vadv.data*batchsize\n",
    "        sum_accuracy += virtual_adversarial_trainer.accuracy(x_batch,y_batch).data*batchsize\n",
    "\n",
    "        if(virtual_adversarial_training==True):\n",
    "            loss = nll+cost_vadv \n",
    "        else:\n",
    "            loss = nll # Maximum Likelihood Estimation\n",
    "            \n",
    "        optimizer.zero_grads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "    optimizer.alpha *=0.9\n",
    "    \n",
    "    sum_test_accuracy = 0\n",
    "    for i in xrange(0, 10000, batchsize):\n",
    "        x_batch = Variable(cuda.to_gpu(x_test[i : i + batchsize]))\n",
    "        y_batch = Variable(cuda.to_gpu(y_test[i : i + batchsize]))\n",
    "        sum_test_accuracy  += virtual_adversarial_trainer.accuracy(x_batch,y_batch).data*batchsize\n",
    "    \n",
    "    print '[epoch ' +  str(epoch) +']' \n",
    "    print 'train nll:' + str(sum_nll/60000) + ' train cost_vadv:' + str(sum_cost_vadv/60000)\n",
    "    print 'train accuracy(%):' + str(sum_accuracy/60000*100) + ' test accuracy(%):' + str(sum_test_accuracy/10000*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Save the computional graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import chainer.computational_graph as c\n",
    "from graphviz import Source\n",
    "g = c.build_computational_graph([loss]).dump()\n",
    "Source(g,filename='computational_graph',).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visualize virtual adversarial perturbations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "xvadv, ptb = virtual_adversarial_trainer.get_virtual_adversarial_examples(x_batch,test=False)\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in xrange(30):\n",
    "    plt.subplot(5,6,i)\n",
    "    plt.imshow(cuda.to_cpu(ptb[i]).reshape((28,28)),cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
